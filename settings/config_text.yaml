# =====================================================================
# settings/config_text.yaml (single source of truth, paper-strict)
# - NO python tuple tags
# - ngram_range kept as list [a,b], code converts to tuple
# =====================================================================

common:
  seed: &seed 42

  split_test_size: &split_test_size 0.2
  length_std_k: &length_std_k 2.5
  min_per_class: &min_per_class 2

  logreg_C: &logreg_C 1.0
  logreg_max_iter: &logreg_max_iter 1000
  max_seq_length: &max_seq_length 512

asr:
  # choose ONE:
  data_root: "/content/NCMMSC2021_AD_Competition-dev/dataset/raw_vad"
  # data_root: "/content/NCMMSC2021_AD_Competition-dev/dataset/raw"
  # data_root: "/content/NCMMSC2021_AD_Competition-dev/dataset/merge"
  # data_root: "/content/NCMMSC2021_AD_Competition-dev/dataset/merge_vad"

  output_csv: "/content/ncmmsc_merged_asr_transcripts.csv"
  model_size: "large-v3"
  device: "cuda"
  compute_type: "float16"

  initial_prompt: |-
    以下是一段中文口語錄音的逐字稿，內容為針對失智症、阿茲海默症、
    輕度認知障礙（MCI）與健康對照組（HC）的臨床訪談與語言測驗，
    包括圖畫描述任務、語意流暢度測驗以及日常生活相關問答。
    請以繁體中文完整逐字轉寫受試者與訪談者的口語內容，不要翻譯、
    不要潤飾或做任何摘要，也不要自行更改語序或補上沒聽到的字。
    請保留口語語氣詞與猶豫聲（例如：嗯、呃、啊、就是、然後）、
    重複、修正、語法不完整或中斷的句子，這些特徵可能與認知功能相關。
    遇到下列專有名詞或相關用語時，請盡量使用常見且一致的寫法：
    「失智症」、「阿茲海默症」、「阿茲海默病」、「輕度認知障礙」、
    「MCI」、「AD」、「HC」、「記憶力」、「認知功能」、
    「量表」、「測驗」、「醫師」、「受試者」、「照顧者」。
    對於 AD、MCI、HC 等縮寫，請以大寫英文字母保留。
    若有單字實在聽不清楚，請不要亂猜，可以以『【聽不清楚】』標示。

  decode:
    language: "zh"
    task: "transcribe"
    beam_size: 10
    patience: 1.0
    length_penalty: 1.0
    temperature: 0.0
    compression_ratio_threshold: 2.4
    log_prob_threshold: -1.0
    no_speech_threshold: 0.6
    condition_on_previous_text: true
    vad_filter: true
    without_timestamps: true

predictive:
  meta_csv: "/content/NCMMSC2021_AD_Competition-dev/2_final_list_train.csv"
  egemaps_csv: "/content/NCMMSC2021_AD_Competition-dev/egemaps_final.csv"
  tsv_root: "/content/NCMMSC2021_AD_Competition-dev/tsv2"
  output_text_jsonl: &predictive_jsonl "/content/Chinese-predictive_challenge_tsv2_output.jsonl"
  output_egemaps_csv: "/content/predictive_egemaps_features.csv"
  dataset_name: "Chinese_predictive_challenge"

  keep_speakers: &pred_keep_speakers ["<B>"]
  tsv:
    keep_speakers: *pred_keep_speakers
    drop_silence: true
    order_by: "no"

text:
  output_dir: "/content/chinese_combined"
  combined_name: "Chinese_Combined.jsonl"
  cleaned_jsonl: "/content/chinese_combined/cleaned.jsonl"

  ncmmsc_jsonl: &ncmmsc_jsonl "/content/chinese_combined/ncmmsc_from_asr.jsonl"

  corpora:
    - name: "NCMMSC2021_AD_Competition"
      path: *ncmmsc_jsonl
    - name: "Chinese_predictive_challenge"
      path: *predictive_jsonl
    - name: "TAUKADIAL"
      path: null

  # 合併」（merge）兩個 text corpora 再一起清理/抽樣/評估
  target_datasets:
    - "NCMMSC2021_AD_Competition"
    - "Chinese_predictive_challenge"

  target_labels: ["AD", "HC"]

  balance: true
  subset_seed: *seed
  cap_per_class: 300

  # label merge：對齊文獻（Probable/Possible -> AD；Control -> HC）
  label_map:
    # ---- HC / Control variants ----
    NC: "HC"
    CN: "HC"
    CTRL: "HC"
    CONTROL: "HC"
    CONTROLS: "HC"
    HEALTHY: "HC"
    NORMAL: "HC"
    "Control": "HC"
    "Controls": "HC"
    "Healthy": "HC"
    "Normal": "HC"
    "HEALTHYCONTROL": "HC"
    "HEALTHY_CONTROL": "HC"
    "HEALTHY CONTROL": "HC"

    # ---- AD variants ----
    PROBABLEAD: "AD"
    POSSIBLEAD: "AD"
    "ProbableAD": "AD"
    "PossibleAD": "AD"
    "PROBABLE_AD": "AD"
    "POSSIBLE_AD": "AD"
    "PROBABLE AD": "AD"
    "POSSIBLE AD": "AD"

    # ---- MCI ----
    MILDCOGNITIVEIMPAIRMENT: "MCI"
    "MildCognitiveImpairment": "MCI"
    "MILD_COGNITIVE_IMPAIRMENT": "MCI"
    "MILD COGNITIVE IMPAIRMENT": "MCI"
    MCI: "MCI"

  language_filter:
    drop_languages: ["en"]

  # prompt filter（解決ASR 混講者用；不影響 tsv 已分離講者的文本）
  prompt_filter:
    enabled: true
    apply_datasets: ["NCMMSC2021_AD_Competition"]
    mode: "leading"
    max_leading_sentences: 8
    min_keep_chars: 20
    patterns:
      # ---- 過濾像訪談指令的句型 ----
      - "(請|麻煩|可以|可不可以|能不能).{0,8}(告訴我|告诉我|描述|說說|说说|講講|讲讲)"
      - "(你|您).{0,8}(看到|看見|看见).{0,12}(圖|图片|圖片|這張|这张|這個|这个|畫面|画面|圖上|图上)"
      - "(他們|他们).{0,10}(在做什麼|在做什么)"
      - "(越多越好|說得越多越好|说得越多越好|講得越多越好|讲得越多越好)"
      - "(你覺得|你觉得).{0,16}(在做什麼|在做什么)"
      - "^(然後呢|然后呢|還有呢|还有呢)"
      - "^(請|麻煩|現在|接下來|接下来).{0,8}(你|您).{0,8}(描述|說|说|講|讲)"
      - "^(請|麻煩).{0,8}(你|您).{0,8}(把|再把|盡量|尽量).{0,8}(看到|看見|看见).{0,12}(告訴我|告诉我|說|说|講|讲|描述)"
      - "^(我們|咱們).{0,10}(來看|来看|看一下|看一看).{0,10}(這張|这张|這個|这个|圖|图|圖片|图片)"
      - "(圖畫|图画).{0,8}(描述|描述任務|描述任务)"
      - "^(請|麻煩).{0,10}(從頭到尾|从头到尾|尽量|盡量).{0,10}(說|说|講|讲|描述)"

  # quality filter (AFTER cleaning + prompt_filter)
  quality_filter:
    enabled: true
    min_chars: 15
    min_lex_chars: 8
    min_han: 6
    max_unk_ratio: 0.75

  length_filter:
    enabled: true
    std_k: *length_std_k
    min_class_n: 30

features:
  tfidf:
    vectorizer:
      analyzer: "char"
      ngram_range: [2, 4]
      lowercase: false
      max_features: 50000
      stop_words: null
      min_df: 1
      max_df: 1.0
    transformer:
      use_idf: true
      smooth_idf: true
      norm: "l2"
      sublinear_tf: false
    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  bert:
    model_name: "/content/models/bert-base-chinese"
    embedding_strategy: "mean"
    pooling: "mean"
    last_n_layers: 4
    max_seq_length: *max_seq_length
    device: "cuda"
    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  glove:
    embeddings_path: "/content/embeddings/cc.zh.300.vec"
    embedding_dim: 300
    tokenizer: "jieba"
    max_words: 50000
    lowercase: false
    remove_stopwords: false
    stopwords_lang: null
    pooling: "sum_l2norm"
    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  gemma:
    model_name: "/content/models/google__gemma-2b"
    pooling: "mean"
    max_seq_length: *max_seq_length
    device: "cuda"
    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  crossval:
    enabled: true
    n_splits: 5
    shuffle: true
    random_state: *seed
    output_indices: "/content/chinese_combined/folds_indices.json"

    methods: ["tfidf", "bert", "glove", "gemma"]

    tfidf_fit_scope: "train"   # "full" | "train"

    batch_size: 8
    bert_batch_size: 8
    gemma_batch_size: 4

    metrics_average: "macro"
    zero_division: 0
    metrics_output: "/content/chinese_combined/cv_metrics.json"

    print_classification_report: true
    print_confusion_matrix: true
    print_method_summary: true
