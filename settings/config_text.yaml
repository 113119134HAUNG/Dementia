# =====================================================================
# config_text.yaml
#
# Central configuration for:
#   1. ASR on NCMMSC audio (Whisper)
#   2. Predictive dataset preprocessing (TSV + eGeMAPS)
#   3. Chinese text preprocessing & dataset merging
#   4. Text features + classifiers + K-fold CV
#      (TF-IDF / BERT / GloVe / Gemma)
# =====================================================================

# ---------------------------------------------------------------------
# Common shared values (single source of truth; reuse via YAML anchors)
# ---------------------------------------------------------------------
common:
  seed: &seed 42

  # preprocessing
  split_test_size: &split_test_size 0.2
  length_std_k: &length_std_k 1.0
  min_per_class: &min_per_class 2

  # modeling (logreg / seq length)
  logreg_C: &logreg_C 1.0
  logreg_max_iter: &logreg_max_iter 1000
  max_seq_length: &max_seq_length 512

# ---------------------------------------------------------------------
#   ASR (audio → transcript CSV) – used by asr_ncmmsc.py
# ---------------------------------------------------------------------
asr:
  data_root: "/content/NCMMSC2021_AD_Competition-dev/dataset/merge"
  output_csv: "/content/ncmmsc_merged_asr_transcripts.csv"

  model_size: "large-v2"
  device: "cuda"            # "cuda" or "cpu"
  compute_type: "float16"   # e.g. "float16", "int8_float16", ...

  initial_prompt: |-
    以下是一段中文口語錄音的逐字稿，內容為針對失智症、阿茲海默症、
    輕度認知障礙（MCI）與健康對照組（HC）的臨床訪談與語言測驗，
    包括圖畫描述任務、語意流暢度測驗以及日常生活相關問答。
    請以繁體中文完整逐字轉寫受試者與訪談者的口語內容，不要翻譯、
    不要潤飾或做任何摘要，也不要自行更改語序或補上沒聽到的字。
    請保留口語語氣詞與猶豫聲（例如：嗯、呃、啊、就是、然後）、
    重複、修正、語法不完整或中斷的句子，這些特徵可能與認知功能相關。
    遇到下列專有名詞或相關用語時，請盡量使用常見且一致的寫法：
    「失智症」、「阿茲海默症」、「阿茲海默病」、「輕度認知障礙」、
    「MCI」、「AD」、「HC」、「記憶力」、「認知功能」、
    「量表」、「測驗」、「醫師」、「受試者」、「照顧者」。
    對於 AD、MCI、HC 等縮寫，請以大寫英文字母保留。
    若有單字實在聽不清楚，請不要亂猜，可以以『[聽不清楚]』標示。

  decode:
    language: "zh"
    task: "transcribe"
    beam_size: 10
    patience: 1.0
    length_penalty: 1.0
    temperature: 0.0
    compression_ratio_threshold: 2.4
    log_prob_threshold: -1.0
    no_speech_threshold: 0.6
    condition_on_previous_text: true
    vad_filter: false
    without_timestamps: true

# ---------------------------------------------------------------------
#    Predictive dataset (TSV + eGeMAPS) – used by preprocess_predictive.py
# ---------------------------------------------------------------------
predictive:
  meta_csv: "/content/predictive/2_final_list_train.csv"
  egemaps_csv: "/content/predictive/egemaps_final.csv"
  tsv_root: "/content/predictive/tsv"
  output_text_jsonl: "/content/Chinese-predictive_challenge_tsv2_output.jsonl"
  output_egemaps_csv: "/content/predictive_egemaps_features.csv"

  # optional TSV parsing knobs (so code doesn't hardcode)
  tsv:
    keep_speakers: null      # e.g. ["<B>"] ; null = keep all
    drop_silence: true       # drop rows where value == "sil"
    order_by: "no"           # "no" | "start_time" | null

  dataset_name: "Chinese_predictive_challenge"

# ---------------------------------------------------------------------
#    Text preprocessing & dataset merging – used by preprocess_chinese.py
# ---------------------------------------------------------------------
text:
  # Inputs
  ncmmsc_jsonl: "/content/data_Chinese-NCMMSC2021_AD_Competition.jsonl"
  predictive_jsonl: "/content/Chinese-predictive_challenge_tsv2_output.jsonl"
  taukadial_jsonl: null      # optional; set a path if available

  # Outputs
  output_dir: "/content/chinese_combined"
  combined_name: "Chinese_NCMMSC_iFlyTek.jsonl"
  train_jsonl: "train_chinese.jsonl"
  test_jsonl: "test_chinese.jsonl"

  # Merge candidates (strict mapping: dataset name ↔ file path)
  corpora:
    - name: "NCMMSC2021_AD_Competition"
      path: "/content/data_Chinese-NCMMSC2021_AD_Competition.jsonl"
    - name: "Chinese_predictive_challenge"
      path: "/content/Chinese-predictive_challenge_tsv2_output.jsonl"
    - name: "TAUKADIAL"
      path: null

  # Subset rules (single source of truth)
  target_datasets: ["NCMMSC2021_AD_Competition"]
  target_labels: ["AD", "HC"]
  balance: true
  subset_seed: *seed
  cap_per_class: 300

  # Label normalization (single source of truth)
  label_map:
    NC: "HC"
    CTRL: "HC"
    CONTROL: "HC"

  # Language filtering
  language_filter:
    drop_languages: ["en"]

  # Length-based outlier filter
  length_filter:
    enabled: true
    std_k: *length_std_k      # keep within mean ± std_k * std

  # Train/test split
  split:
    test_size: *split_test_size
    random_state: *seed
    stratify: true
    min_per_class: *min_per_class
  
# ---------------------------------------------------------------------
#    Text features + classifiers + K-fold cross-validation
# ---------------------------------------------------------------------
features:
  method: "bert"

  tfidf:
    vectorizer:
      lowercase: true
      max_features: 20000
      ngram_range: [1, 2]
      stop_words: null
      min_df: 1
      max_df: 1.0

    transformer:
      use_idf: true
      smooth_idf: true
      norm: "l2"
      sublinear_tf: false

    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  bert:
    model_name: "bert-base-chinese"
    pooling: "mean"
    max_seq_length: *max_seq_length
    device: "cuda"

    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  glove:
    embeddings_path: "/path/to/Glove/glove300.txt"
    embedding_dim: 300
    lowercase: true
    remove_stopwords: true
    stopwords_lang: "english"
    pooling: "sum_l2norm"

    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  gemma:
    model_name: "google/gemma-2b"
    pooling: "mean"
    max_seq_length: *max_seq_length
    padding: "longest"
    truncation: true
    device: "cuda"

    logreg:
      C: *logreg_C
      class_weight: "balanced"
      solver: "lbfgs"
      max_iter: *logreg_max_iter
      random_state: *seed

  crossval:
    enabled: true
    n_splits: 5
    stratified: true
    shuffle: true
    random_state: *seed
    metrics_average: "macro"
